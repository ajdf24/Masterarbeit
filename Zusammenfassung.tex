\section{Zusammenfassung}
Die vorliegende Arbeit beschäftigt sich mit der Frage, ob es möglich ist mit aktuellen \ac{AR} und \ac{AI} Technologien ein \ac{NUI} vor erstellen, welches allein durch Gesten und Sprachbefehle gesteuert werden kann.

Hierbei wird zuerst die Frage geklärt, was genau ein \ac{NUI} ist. In diesem Zusammenhang wird gezeigt, dass es möglich ist auch ein \ac{NUI} anhand der EN ISO 9241 validiert werden kann.

Beginnend mit einem Überblick zu Mixed Reality werden später die beiden Gerätetypen Handheld und Video-See-Through-Display genauer beschrieben. Es wird untersucht, auf welchem Gerät sich ein \ac{NUI} mit Gesten und Sprache am besten umgesetzt werden kann. Die Wahl fiel auf die HoloLens, welche aktuell die beste Hardware- und Software-Unterstützung besitzt.

Als nächstes wurden unterschiedliche \ac{AI}-Technologien verglichen. Der Fokus lag hierbei auf den vier aktuellen Digitalen Assistenten Amazon Alexa, Apple Siri, Microsoft Cortana und der Google Assistent. Es wurde hier auf die Funktionsweise und eine mögliche Anbindung über APIs eingegangen. Wobei sich zeigte das Siri und Cortana aktuell durch nicht öffentliche Schnittstellen nicht in Frage kommen. Der Google Assistent und Alexa sind aktuell technologisch gleich auf und können ähnlich viel leisten.

Nachdem die Technischen Grundlagen und Möglichkeiten evaluiert waren, wurde ein konkretes \ac{NUI} beschrieben. Aus verschiedenen beschriebenen möglichen Einsatzgebieten wurde ein Architektureditor gewählt, welcher prototypisch stark vereinfacht wurde um zu zeigen, dass es machbar ist ein \ac{NUI} auf Basis der HoloLens zu entwickeln. 

Es wurden mögliche Gesten und Sprachbefehle beschrieben, die es möglich machen einen nach dem Minecraft-Prinzip funktionierenden Block-Editor zu bedienen. 

In der Entwicklungsphase wurde zuerst auf die grundlegende Entwicklung einer Unity-Szene für die HoloLens eingegangen. Daraufhin wurde festgestellt, dass die HoloLens, die für das \ac{NUI} entwickelten Gesten, nicht umsetzen kann. Aus diesem Grund, musste die Gesten-Bedienung für die HoloLens umgearbeitet werden. Anhand von Code-Beispielen wird gezeigt, wie die Implementierung genau funktioniert. Abschließend wird auf Probleme bei der Entwicklung und mögliche Lösungen eingegangen.

Beim abschließenden Fazit wurde darauf eingegangen, welche grundlegenden Probleme sich während der Erarbeitung des \ac{NUI} aufgetreten sind und wie sie sich lösen lassen. 