\section{Beschreibung eines Natural User Interface}\label{Beschreibung eines Natural User Interface}
Im foldenden Kapitel werden verschiedene mögliche Einsatzgebiete für ein \ac{NUI} mit aktuellen \ac{AR} und \ac{AI}-Technologien beschrieben. 
Anhand eines Einsatzgebietes wird dann ein \ac{NUI} genauer beschrieben und designed.

\subsection{Einsatzgebiete}
Um überhaupt ein \ac{NUI} erstellen und beschreiben zu können, muss ein spezielles Szenario gewählt werden, an das Gesten und Sprachkommandos angepasst werden.

\subsubsection{Architektur Designer}
Schon heute gibt es unzählige Programme, mit dem Gebäude designt werden können. Eines davon ist "`Architekt 3D"', mit dem nicht nur Modelle erstellt werden können, sondern auch Grund- und Auf-risse erzeugt werden können.

\begin{figure}[!ht]
\centering
\includegraphics[width=10cm]{Bilder/architek_3d.png}
\caption{Darstellung eines Hauses in Architekt 3D \cite{Arch3D}}
\label{arch_3d}
\centering
\end{figure}

In Abbildung \ref{arch_3d} ist die Darstellung eines Hauses zu sehen, welches mit "`Architekt 3D"' erstellt wurde. In einer \ac{AR}-Umgebung mit einem \ac{NUI} wäre es jetzt zum Beispiel möglich, um das Hologramm des Gebäude herum zu gehen oder es per Sprachbefehl vergrößern oder verkleinern. Es könnte auch möglich sein, zum Beispiel Leitungen einzublenden.

Mit Gesten könnte es ebenso möglich werden, Fenster und Türen zu verschieben oder Objekte zu selektieren. 

Aber selbst das Designen von Grund auf ist innerhalb einer \ac{AR}-Anwendung kein Problem. Über ein Sprachkommando könnten zum Beispiel Wände ausgewählt werden, welche dann über Gesten im Raum gesetzt, verschoben oder gelöscht werden können.

Das System könnte ähnlich wie "`Google Blocks"' mit welchem es unter Verwendung der "`Oculus Rift"' oder der "`HTC Vive"' möglich ist, 3D-Modelle zu erstellen, gestaltet werden.
\cite{Blocks}

\subsubsection{Bauen im Bestand}
Eine weitere Anwendungsmöglichkeit für ein verwandtes System wäre das Bauen im Bestand, also wenn schon bestehende Häuser verändert und modifiziert werden sollen. Mit Hilfe von Sprachbefehlen könnte man bestehende Strom oder Rohrleitungen unter den Wänden anzeigen, um zu sehen, welche baulichen Veränderungen getroffen werden können und welche nicht. 

So ist es zum Beispiel möglich, neue Leitungen zu planen ohne alte zu beschädigen oder suchen zu müssen. 

\begin{figure}[!ht]
\centering
\includegraphics[width=10cm]{Bilder/ikea.jpg}
\caption{Ikea's \ac{AR} Möbelstücke \cite{IkeaVideo}}
\label{ikea_video}
\centering
\end{figure}

Es wäre möglich, zum Beispiel Küchenzeilen in Räumen zu platzieren, um zu zeigen, wie diese ausfallen und ob sie zum Raum passen. Ein Vorreiter in dieser Technik ist die Möbelhauskette Ikea. Seit 2014 können Kunden von Ikea den Katalog mit der Ikea eigenen App scannen und so Möbelstücke auswählen, welche dann wiederum als \ac{AR}-Objekt in der eigenen Wohnung angesehen werden können. In Abbildung \ref{ikea_video} ist die Ikea-App zu sehen, in der Nutzer \ac{AR}-Möbel in ihrer Wohnung platzieren.
\cite{Ikea}

\subsubsection{Unterstützung von Rettungskräften}
Feuerwehrleute rücken täglich aus, um unser aller Leben zu retten, sollten wir einmal in eine Gefahrensituation geraten. In stark verqualmten Räumen suchen Feuerwehrleute zum Beispiel nach Überlebenden. Hilfreich wäre hier zum Beispiel ein Gerät, welches unter schlechter Sicht, den Raum Scannt und Hindernisse, wie Tische, Schränke oder aber weitere Türen anzeigt. 

Über Sprachbefehle wäre es zum Beispiel möglich, den Raum zu Scannen und zu Visualisieren. Eine andere Möglichkeit wäre, anhand von Wärmesignaturen nach Überlebenden zu suchen. 

Ein solcher Einsatz liegt jedoch noch in weiter Ferne, da hierfür Geräte entwickelt werden welche Räume auch unter schlechter Sicht zuverlässig scannen und zum anderen auch Wärmebilder verarbeiten können. 

Momentan sind Aktuelle \ac{AR}-Geräte noch nicht in der Lage unter solchen Situation zu arbeiten, geschweige den dass sie den harten Einsatz überstehen würden. Denn Wasser, Staub, Hitze und harte Stöße sind noch immer der Feind von solchen Geräten.

\subsubsection{Bestmögliches Beispiel}
Es wurden drei mögliche Beispiele beschrieben, Anhand von denen ein Prototyp entwickelt werden kann, welcher genau aufzeigt, in wie weit ein \ac{NUI} mit aktuellen \ac{AR} und \ac{AI} Technologien erstellt werden kann und welche Stärken und Schwächen es hat.

Der dringendste Bedarf für eine Applikation hat mit Sicherheit die Feuerwehrleute, welche unter Einsatz ihres Lebens arbeiten. Leider gibt es für eine solche Anwendung noch keine Hardware. Nicht nur, dass aktuelle \ac{AR}-Brillen heute nur bei guter Sicht arbeiten, sie verfügen auch nicht über die Möglichkeit, Wärmebilder zu erstellen, weshalb dieser Ansatz nicht weiter verfolgt wird.

Das Bauen im Bestand mit \ac{AR} ist natürlich sehr nützlich. Jedoch ist das Rahmenwerk, welches als Vorarbeit geleistet werden muss, vom Umfang zu groß für diese Arbeit. Es müsste eine Raumerkennung entwickelt werden, welche zuverlässig Türen und Fenster erkennt. Außerdem müssen erst Beispieldaten für Leitungsnetze von Räumen angelegt werden. 

Am besten eignet sich der Architektur Editor. Es ist heute relativ einfach möglich, ein grundlegendes Design Programm zu erstellen, welches Objekte erstellen oder verändern kann. 
Dieses System, kann dann um ein \ac{NUI} erweitert werden.

\subsection{Erstellung eines Architektur Editor als Prototyp}\label{Erstellung eines Architektur Editor als Prototyp}
Natürlich ist es innerhalb der Arbeit nicht möglich, einen realistischen Architektur Editor zu erstellen, mit dem es möglich wird hochauflösende \ac{AR}-Modelle von Gebäuden zu designen.
Hierauf liegt auch nicht das Augenmerk der Arbeit. 

Umgesetzt werden soll ein 3D-Designer, mit welchem es ähnlich wie im Spiel "`Minecraft"' möglich ist, verschiedene \ac{AR}-Blöcke in der realen Welt zu platzieren, um hiermit  Gegenstände designen zu können.

Der entstehende prototypische Designer soll dann später nur über Gesten und Sprache gesteuert werden können. Hierfür werden folgende Gesten und Sprachbefehle benötigt.

Gesten: 
\begin{itemize}
 \item Block setzen
 \item Block entfernen
 \item Objekt drehen
\end{itemize}

Sprachbefehle:
\begin{itemize}
 \item Block Material auswählen
\end{itemize}

Es ergeben sich für den reinen Design Einsatz also drei Gesten und ein Sprachbefehl. Mit den Gesten ist es möglich, Blöcke zu setzen, zu entfernen und das gesamte Objekt zu drehen. Mit einem Sprachbefehl kann das Material der Blöcke geändert werden. 

Aber ein \ac{NUI} macht nicht nur aus, dass es mit Gesten und Sprache gesteuert werden kann. Es muss sich auch auf den Nutzer einlassen und Fehlertolerant sein. Das heißt im Umkehrschluss, es muss auch möglich sein Gesten durch Sprache zu ersetzen und umgekehrt. Hieraus ergeben sich weitere Gesten und Sprachbefehle:

Gesten: 
\begin{itemize}
 \item Block Material auswählen
\end{itemize}

Sprachbefehle:
\begin{itemize}
 \item Block setzen
 \item Block entfernen
 \item Objekt drehen
\end{itemize}

Es ergeben sich also aus vier Bedienmöglichkeiten acht mögliche Bedienszenarien für das reine Designen. Ob alle Möglichkeiten umgesetzt werden, wird sich in der späteren Bedienung herausstellen. Eventuell sind Gesten zum Auswählen des Materials nicht sinnvoll und praktikabel ebenso wie das Setzen und Entfernen von Blöcken über Sprache. 

\subsection{Beschreibung der Gesten und Sprachkommandos}\label{Beschreibung der Gesten und Sprachkommandos}
Nachdem alle Steuerungstypen für den Prototyp festgelegt wurden, muss nun eine genaue Beschreibung erfolgen. Im ersten Schritt geht es rein um die grundlegende Erstellung von Gesten und Sprachkommandos, ohne technische Plattformen oder Limitierungen einzubeziehen. Dies geschieht anschließend im Kapitel ?????.

\subsubsection{Gesten}
Gesten, welche innerhalb eines \ac{NUI} implementiert werden, müssen selbsterklärend sein. Somit muss eine Geste gefunden werden, welche möglichst in der realen Welt genau das tut, was auch im Computer getan werden soll.

\paragraph{Setzen und Entfernen}
Um leichte Gegenstände zu platzieren, werden diese Gegenstände von Menschen zwischen Daumen und Zeigefinger - größere oder schwerere Gegenstände auch schon mal unter Zuhilfenahme des Mittelfingers - gegriffen und auf der gewünschten Stelle platziert. Siehe Abbildung \ref{chess_hand}.

\begin{figure}[!ht]
\centering
\includegraphics[width=10cm]{Bilder/chess_hand.png}
\caption{Platzieren eines Gegenstandes mit der Hand \cite{ChessPlacing}}
\label{chess_hand}
\centering
\end{figure}

Ohne die entsprechende Schachfigur ergeben sich dann Gesten wie diese. In Abbildung \ref{placing_1} ist die entsprechende Geste mit geschlossener Hand zu sehen, wobei in Abbildung \ref{placing_2} die Hand geöffnet ist. Die Bedeutung der Gesten ist jedoch die selbe.

\begin{figure}[!ht]
\centering
\includegraphics[width=5cm]{Bilder/placing_1.jpg}
\caption{Platzierende Geste Variante 1 \cite{Placing1}}
\label{placing_1}
\centering
\end{figure}

\begin{figure}[!ht]
\centering
\includegraphics[width=5cm]{Bilder/placing_2.jpg}
\caption{Platzierende Geste Variante 2 \cite{Placing2}}
\label{placing_2}
\centering
\end{figure}

\FloatBarrier

Werden die Finger nun geöffnet, wird der Gegenstand abgesetzt und die Position nicht weiter verändert. Der Block ist gesetzt.

Umgekehrt funktioniert die Geste genau so. Werden die Finger innerhalb eines Blocks geschlossen, wird dieser selektiert und kann danach verschoben oder entfernt werden.
Menschen entfernen Gegenstände, indem sie diese greifen und dann woanders ablegen. Der Prototyp kann einen Stein, der losgelassen wird und dann in der Luft ist, als gelöscht interpretieren. 

\paragraph{Objekte drehen}

Um Objekte auf einer Fläche zu drehen, nutzen Menschen in der Regel den Zeigefinger, um das Objekt auf einer Seite anzustoßen. Dieser Impuls dreht dann das entsprechende Objekt. Für das \ac{NUI} bedeutet das also, dass ein ausgestreckter Zeigefinger, der in der Luft rotiert, das Objekt rotieren soll. In Abbildung \ref{rotate_1} ist diese Geste einmal schematisch dargestellt.

\begin{figure}[!ht]
\centering
\includegraphics[width=5cm]{Bilder/rotate1.png}
\caption{Rotieren Variante 1 \cite{Rotate1}}
\label{rotate_1}
\centering
\end{figure}

Das Objekt kann aber auch noch auf eine andere Art gedreht werden. Menschen können ein Gegenstand auch zwischen Daumen und Zeigefinger einklemmen und es dann durch eine Drehung der Hand drehen. 

Im Umkehrschluss bedeutet dies, dass auch diese Geste bekannt sein muss. Das \ac{NUI} muss entsprechend zwei drehende Finger auch als Kommando zum Drehen auffassen. In Abbildung \ref{rotate_2} ist diese Geste dargestellt. 

\begin{figure}[!ht]
\centering
\includegraphics[width=5cm]{Bilder/rotate2.jpg}
\caption{Rotieren Variante 2 \cite{Rotate2}}
\label{rotate_2}
\centering
\end{figure}

\subsubsection{Sprachkommandos}\label{Beschreibung Sprachkommandos}
Sprachkommandos sind Sätze, welche von einem \ac{NUI} als Eingabe verarbeitet werden und Aktionen auslösen. Grammatikalisch muss ein Satz mindestens aus zwei Bestandteilen bestehen, dem Subjekt, also das was verändert wird, und dem Prädikat, das angibt was getan werden soll. Somit müssen auch alle Sprachkommandos mindestens aus zwei Worten bestehen. Der Nutzer muss also angeben, was verändert werden soll und wie es verändert werden soll. 

Somit ergeben sich für den konkreten Einsatzzweck folgende grundlegende Befehle. 
\begin{itemize}
 \item Block setzen
 \item Block entfernen
 \item Objekt drehen 
 \item Material ändern
\end{itemize}

Die ersten drei Befehle sind eindeutig. Es ist klar, dass der selektierte Objekt gesetzt, entfernt oder gedreht werden soll. Ist nichts selektiert, kann der Befehl nicht ausgeführt werden. Andernfalls hat die Eingabe des Sprachkommandos eine unmittelbare Folge.

Das Ändern des Materials hingegen ist komplexer. Der Befehl hat eine Variable, nämlich die Art des Materials. Das Material muss im Programm bekannt sein, um es auswählen zu können. Somit ist der Satz "`Ändere das Material zu Stein."' ein eindeutiger Befehl. Das Interface muss jedoch so programmiert werden, dass der Auslöser "`Ändere das Material"' ist. "`Stein"' muss zusätzlich erkannt werden, denn diese Variable enthält die eigentliche Information. 

Ist der Auslöser richtig erkannt worden, so muss das Interface das entsprechende Material wählen. Ist das Material dem Programm nicht bekannt, so muss es dies an den Nutzer kommunizieren. 

Sprache ist jedoch nicht so eindeutig wie Gesten. Wörter können zum Beispiel mit Dialekt ausgesprochen werden. Wodurch die Erkennung um einiges schwieriger wird. Diese Zuordnung übernehmen jedoch Frameworks. Programmierer müssen sich heute nicht mehr darum kümmern das ein Wort unterschiedlich ausgesprochen werden kann. 

Alle heutigen Sprachassistenten Nutzen für diese Erkennung lernende Algorithmen, welche durch die Nutzung ständig verbessert werden. 

Worum sich Programmierer aber immer noch kümmern müssen, sind synonyme Wörter, welche verwendet werden können. Von einem \ac{NUI} wird erwartet, das es Synonyme erkennt und dennoch den richtigen Befehl ausführt. 

Das Wort "`setzen"' hat laut Duden folgende Synonyme:
\begin{itemize}
 \item platzieren
 \item postieren
 \item hintun
 \item absitzen
 \item abhocken
 \item eingraben
 \item einpflanzen
 \item einsetzen
 \item stecken
 \item sedimentieren
 \item wetten
 \item tippen
\end{itemize}

Die Wörter "`wetten"' und "`tippen"' beziehen sich eindeutig auf das "`setzen"' einer Wette und sind somit keine echten Alternativen für ein \ac{NUI}. Ebenso verhält es sich mit eingraben, einpflanzen, einsetzen, stecken und sedimentieren. Diese Wörter beziehen sich eindeutig auf das "`setzen"' einer Pflanze. "`Absitzen"' und "`abhocken"' stammen aus der schweizerischen Mundart, sind aber auch in Deutschland gebräuchlich. Sie beziehen sich auf das hinsetzen einer Person und sich somit auch nicht als Alternativen für ein \ac{NUI} vergesehen. 
"`Platzieren"', "`postieren"' und "`hintun"' hingegen sind eindeutige Alternativen für das angedachte \ac{NUI}. Es ist durchaus aus im Bereich des möglichen, dass ein Nutzer "`Block platzieren"' oder "`Block postieren"' an Stelle von "`Block setzen"' sagt. Das Interface muss also bei den Befehlen:

\begin{itemize}
 \item Block setzen
 \item Block postieren
 \item Block platzieren
 \item Bock hintun
\end{itemize}

immer einen Block setzen. 

Wenn man das Schema weiter verfolgt, so ergeben sich auf für den Befehl "`Block entfernen"' Synonyme Befehle:

\begin{itemize}
 \item Block entfernen
 \item Block löschen
 \item Block tilgen
 \item Bock wegtun
\end{itemize}

Für "`Objekt drehen"' kommen noch einmal folgende Befehle hinzu:

\begin{itemize}
 \item Objekt drehen
 \item Objekt rotieren
\end{itemize}

Aus den ehemals vier grundlegenden Befehlen (siehe Abschnitt \ref{Erstellung eines Architektur Editor als Prototyp}) sind schon 10 geworden, nur damit sich das Interface "`Natürlich"' bedienen lässt.

Sprache erlaubt es aber auch Wörter zu trennen, so kann zum Beispiel der Befehl "`Block hintun"' auch "`Tue den Block hin"' lauten, ohne das sich an der Bedeutung des Befehls etwas ändert. 
Um dies umzusetzen gibt es technisch gesehen verschiedene Möglichkeiten. 

Eine ist die so genannte \ac{SRGS} des \ac{W3C}, welche Sprachen grammatikalisch beschreiben. Hier können in \ac{XML} konformer weise, Wortschemen eingegeben werden, um einer Maschine zu verstehen zu geben, wie ein Mensch, einen Befehl aussprechen würde. 

Hierbei werden Regeln aufgeführt, welche dann verschieden verkettet werden können, um Sätze zu bilden. Über ein solches \ac{XML} können unter anderem auch verschiedene Sprachen und Dialekte abgebildet werden.

\subsection{Überprüfung der Gesten und Sprachkommandos}
Im folgenden werden die beschriebenen Gesten und Sprachkommandos anhand der ISO 9241 Teil 110 überprüft.


\subsubsection{Gesten}
\begin{minipage}{4cm}
 \textbf{Grundsätze}
\end{minipage}\hspace{0.5cm}
\begin{minipage}{5.5cm}
 \textbf{Setzen / Entfernen}
\end{minipage}\hspace{0.5cm}
\begin{minipage}{5.5cm}
 \textbf{Drehen}
\end{minipage}
\\\\
\begin{minipage}{4cm}
\vspace{0.5cm}
 Aufgaben-angemessenheit
\end{minipage}\hspace{0.5cm}
\begin{minipage}{5.5cm}
\vspace{0.5cm}
 Das bewegen der Hand, sowie das interagieren auf der entsprechenden Stelle, wo sich der Block befindet, sind einfach auszuführen und der Aufgabe angemessen, da der Block um den des geht virtuel berührt werden soll.
\end{minipage}\hspace{0.5cm}
\begin{minipage}{5.5cm}
\vspace{0.5cm}
 Die Bewegung der Finger ist eine einfache Geste, welche Objekte drehen sollen. Sie ist einfach gehalten und den Bewegungen von Smartphones nachempfunden.
\end{minipage}
\\\\
\begin{minipage}{4cm}
\vspace{0.5cm}
 Selbstbeschreibungs-fähigkeit
\end{minipage}\hspace{0.5cm}
\begin{minipage}{5.5cm}
\vspace{0.5cm}
 Die Geste ist selbst beschreibend, wenn der Bock auf der Position der Finger projeziert wird. Durch das Drücken wird entsprechend der Block gesetzt oder entfernt.
\end{minipage}\hspace{0.5cm}
\begin{minipage}{5.5cm}
\vspace{0.5cm}
 Das Drehen der Finger ist nicht ganz Selbstbechreibend, jedoch gleicht das adaptive \ac{NUI}, welche die Geste interpretierert dies wieder aus, so dass eintsprechend eine Drehbewegung erkannt werden kann.
\end{minipage}
\\\\
\begin{minipage}{4cm}
\vspace{0.5cm}
 Steuerbarkeit
\end{minipage}\hspace{0.5cm}
\begin{minipage}{5.5cm}
\vspace{0.5cm}
 Wird ein Block versehentlich gesetzt, so kann dies auch wieder rückgängig gemacht werden, da ein Block zu jeder Zeit wieder entfernt werden kann.
\end{minipage}\hspace{0.5cm}
\begin{minipage}{5.5cm}
 \vspace{0.5cm}
 Die Drehung kann ebenso wie das Setzen und Entfernen rückgängig gemacht werden, indem eine Drehung in die entgegengesetzte Richtung gemacht wird.
\end{minipage}
\\\\
\begin{minipage}{4cm}
\vspace{0.5cm}
 Erwartungskonformität
\end{minipage}\hspace{0.5cm}
\begin{minipage}{5.5cm}
\vspace{0.5cm}
 Die Geste ist Erwartungskonform zur realität gehalten und somit Erwartungskonform in jeder Hinsicht, da keine andere Handlung ausgeführt wird.
\end{minipage}\hspace{0.5cm}
\begin{minipage}{5.5cm}
\vspace{0.5cm}
 Das Drehen ist ebenso Erwartungskonform, da beim drehen keine andere Handlung ausgeführt wird.
\end{minipage}
\\\\
\begin{minipage}{4cm}
\vspace{0.5cm}
 Fehlertoleranz
\end{minipage}\hspace{0.5cm}
\begin{minipage}{5.5cm}
\vspace{0.5cm}
 Durch die Wiederholung der Geste auf der selben Stelle kann ein versehentlich gelöschter oder gesetzter Block wieder gesetzt oder entfernt werden.
\end{minipage}\hspace{0.5cm}
\begin{minipage}{5.5cm}
\vspace{0.5cm}
 Das Drehen in die Gegenrichtung bewirkt, dass die Wirkung der ersten Drehung aufgehoben wird.
\end{minipage}
\\\\
\begin{minipage}{4cm}
\vspace{0.5cm}
 Individualisierbarkeit
\end{minipage}\hspace{0.5cm}
\begin{minipage}{5.5cm}
\vspace{0.5cm}
 Durch das \ac{NUI} wird eine Ungenauigkeit der Nutzer abgefangen. Jedoch ist die Geste so eindeutig, dass sie nicht weiter Individualisierbar ist.
\end{minipage}\hspace{0.5cm}
\begin{minipage}{5.5cm}
\vspace{0.5cm}
 Für das Drehen gibt es zwei verschiedene Möglichkeiten wie diese Geste umgesetzt werden kann. Über das \ac{NUI} werden auch hier Ungenauigkeiten von Seiten der Nutzer ausgeglichen.
\end{minipage}
\\\\
\begin{minipage}{4cm}
\vspace{0.5cm}
 Lernförderlichkeit
\end{minipage}\hspace{0.5cm}
\begin{minipage}{5.5cm}
\vspace{0.5cm}
 Da die Geste zum Setzen und entfernen aus der realen Welt stammen, sind sie eindeutig und ohne Probleme zu verstehen.
\end{minipage}\hspace{0.5cm}
\begin{minipage}{5.5cm}
\vspace{0.5cm}
 Das Drehen mittels einen oder zwei Finger ist grundsätzlich auch aus der Natur gegriffen. Da die Gesten auch auf Smartphones verwendet werden, sind auch diese schon bekannt.
\end{minipage}

\subsubsection{Sprachkommandos}
Sprache ist zwar nicht immer eindeutig, jedoch wird sie dies im Kontext betrachtet. Befehle, welche also zu einem \ac{NUI} gesprochen werden, werden entweder Verstanden und ausgeführt oder nicht. Weshalb eine Überprüfung anhand der ISO 9241 Teil 110 nicht sinnvoll ist.

Durch die Verwendung von synonymen Wörtern (siehe Abschnitt \ref{Beschreibung Sprachkommandos}) wird das Verständnis von Sprachbefehlen durch ein \ac{NUI} um einiges erweitert, was eine bessere Verwendbarkeit nach sich zieht.


